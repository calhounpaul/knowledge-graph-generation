FROM huggingface/transformers-pytorch-gpu
#FROM nvidia/cuda:12.1.0-cudnn8-devel-ubuntu22.04
#FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu20.04

ARG DEBIAN_FRONTEND=noninteractive

#SHELL ["sh", "-lc"]

RUN apt update
RUN apt install -y git python3 python3-pip

RUN python3 -m pip install --no-cache-dir --upgrade pip

RUN python3 -m pip install --no-cache-dir llama-index llama-index-readers-file llama-index-embeddings-huggingface llama-index-llms-huggingface

ARG REF=main

WORKDIR /root

RUN apt install -y curl

RUN apt install -y tmux wget

RUN python3 -m pip install --no-cache-dir transformers[torch] huggingface_hub[inference]
RUN python3 -m pip install --no-cache-dir autoawq bitsandbytes accelerate peft